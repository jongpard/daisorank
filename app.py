# -*- coding: utf-8 -*-
"""
daisorang/app.py (ìˆ˜ì •ë³¸ ì „ì²´)
- TopN=200 ë¬´ì¡°ê±´ ë³´ì¥
- analyze_trends() ë°˜í™˜ê°’ 6ê°œë¡œ í†µì¼ (ì–¸íŒ© ì—ëŸ¬ í•´ê²°)
- INâ‰¡OUT ê·œì¹™ ê°•ì œ ë° ìŠ¬ë™ í¬ë§·(ë³¼ë“œ í•œ ì¤„ ìš”ì•½)
- êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì„±ê³µ í›„ì—ë„ íŒŒì´í”„ë¼ì¸ì´ 'ì‹¤íŒ¨'ë¡œ ëë‚˜ì§€ ì•Šë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬ ê°œì„ 
"""

import os
import sys
import csv
import json
import time
import math
import traceback
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Tuple, Optional

# -----------------------------
# í™˜ê²½ ë³€ìˆ˜
# -----------------------------
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL", "")
GDRIVE_FOLDER_ID   = os.getenv("GDRIVE_FOLDER_ID", "")
SITE_NAME          = os.getenv("SITE_NAME", "daisomall")  # ë¡œê¹…ìš©
TOPN               = int(os.getenv("TOPN", "200"))

KST = timezone(timedelta(hours=9))

# -----------------------------
# ìœ í‹¸
# -----------------------------
def kst_today_str(fmt: str = "%Y-%m-%d") -> str:
    return datetime.now(KST).strftime(fmt)

def safe_int(v, default=999999):
    try:
        return int(v)
    except Exception:
        try:
            return int(float(v))
        except Exception:
            return default

def ensure_dir(path: str):
    d = os.path.dirname(path)
    if d and not os.path.exists(d):
        os.makedirs(d, exist_ok=True)

# -----------------------------
# ìˆ˜ì§‘(í˜ì´ì§€ë„¤ì´ì…˜ ì½œë°±)
#  - ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ í˜ì´ì§• í•¨ìˆ˜ì— ë§ì¶° ë‚´ìš©ì„ ì—°ê²°í•˜ì„¸ìš”.
#  - í˜„ì¬ëŠ” 'ë„ˆì˜ ê¸°ì¡´ ëª¨ë“ˆ'ì— ì´ë¯¸ ìˆëŠ” í•¨ìˆ˜ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  import ì‹œë„,
#    ì—†ìœ¼ë©´ ê°„ë‹¨ ìŠ¤í…ìœ¼ë¡œ ë™ì‘(ì‹¤ì„œë¹„ìŠ¤ì—ì„  ë°˜ë“œì‹œ ë„ˆì˜ ì‹¤ì œ í•¨ìˆ˜ë¡œ ë°”ê¿”ì¤˜).
# -----------------------------
def _stub_fetch_next_page(page: int) -> List[Dict[str, Any]]:
    """
    [ì„ì‹œ ìŠ¤í…] ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„  ë°˜ë“œì‹œ ê¸°ì¡´ì˜ í¬ë¡¤ëŸ¬ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
    ë°˜í™˜ ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ: {"key": "...", "raw_name": "...", "rank": 1, "url": "...", "price": "...", ...}
    """
    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ëŒë ¤ ì¬ì‹œë„/ë³´ì¥ ë¡œì§ì´ ì‘ë™í•˜ë„ë¡ í•¨
    return []

try:
    # ì˜ˆ: from crawler import fetch_next_page
    from crawler import fetch_next_page as fetch_next_page_impl  # type: ignore
except Exception:
    fetch_next_page_impl = _stub_fetch_next_page

def fetch_next_page(page: int) -> List[Dict[str, Any]]:
    return fetch_next_page_impl(page=page)

# -----------------------------
# TopN ë³´ì¥
# -----------------------------
def ensure_topN(rows: List[Dict[str, Any]],
                topN: int = TOPN,
                site_name: str = SITE_NAME,
                max_retry: int = 3,
                fetch_fn=None) -> List[Dict[str, Any]]:
    """
    rowsê°€ topN ë¯¸ë§Œì´ë©´ fetch_fn(page=2,3,...)ë¡œ ì¶”ê°€ ìˆ˜ì§‘ ì‹œë„.
    ìµœì¢… ë¯¸ë‹¬ì´ë©´ ëª…í™•í•œ ì˜ˆì™¸ë¡œ ì¤‘ë‹¨(ì›ì¸ íŒŒì•… ì‰¬ì›€).
    """
    if rows is None:
        rows = []
    # rankê°€ ìˆ«ìì¸ ê²ƒë§Œ
    rows = [r for r in rows if isinstance(r.get("rank"), (int, float, str))]
    for r in rows:
        r["rank"] = safe_int(r.get("rank"))

    rows = sorted(rows, key=lambda r: safe_int(r.get("rank")))
    rows = rows[:topN]

    attempt = 1
    while len(rows) < topN and attempt <= max_retry:
        if fetch_fn is None:
            break
        more = fetch_fn(page=attempt + 1) or []
        # ì •í•©ì„±
        for m in more:
            m["rank"] = safe_int(m.get("rank"))
        rows += more
        rows = [r for r in rows if isinstance(r.get("rank"), (int, float))]
        rows = sorted(rows, key=lambda r: safe_int(r.get("rank")))[:topN]
        attempt += 1

    if len(rows) < topN:
        raise RuntimeError(
            f"[ìˆ˜ì§‘ ì—ëŸ¬] Top{topN} ë³´ì¥ ì‹¤íŒ¨: í˜„ì¬ {len(rows)}ê°œ. "
            f"ìˆ˜ì§‘ ì†ŒìŠ¤({site_name}) êµ¬ì¡° ë³€ê²½/ì°¨ë‹¨/í’ˆì ˆ ê³µë€ ê°€ëŠ¥ì„±. ë¡œê·¸ í™•ì¸ í•„ìš”."
        )

    return rows

# -----------------------------
# ì „ì¼ ë°ì´í„° ë¡œë”©
#  - í”„ë¡œì íŠ¸ ì‚¬ì–‘ì— ë§ê²Œ êµ¬í˜„í•˜ì„¸ìš”.
#  - ì—¬ê¸°ì„  ë¡œì»¬ CSV ìš°ì„ , ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸.
# -----------------------------
def load_prev_list(csv_path: str) -> List[Dict[str, Any]]:
    if not os.path.exists(csv_path):
        return []
    out = []
    with open(csv_path, "r", encoding="utf-8-sig", newline="") as f:
        reader = csv.DictReader(f)
        for r in reader:
            r = dict(r)
            r["rank"] = safe_int(r.get("rank"))
            out.append(r)
    return out

# -----------------------------
# ë¶„ì„: ìƒìŠ¹/í•˜ë½/IN/OUT (ë°˜í™˜ê°’ 6ê°œë¡œ í†µì¼)
# -----------------------------
def analyze_trends(rows: List[Dict[str, Any]],
                   prev_list: List[Dict[str, Any]],
                   topN: int = TOPN
                   ) -> Tuple[List[Dict[str, Any]],
                              List[Dict[str, Any]],
                              List[Dict[str, Any]],
                              List[Dict[str, Any]],
                              List[Dict[str, Any]],
                              int]:
    """
    return: (today_aug, ups, downs, chart_ins, rank_outs, io_cnt)
    - today_aug: ì˜¤ëŠ˜ TopN ì •ëˆ ë¦¬ìŠ¤íŠ¸
    - ups: ì „ì¼ ëŒ€ë¹„ ìƒìŠ¹
    - downs: ì „ì¼ ëŒ€ë¹„ í•˜ë½
    - chart_ins: ì‹ ê·œ ì§„ì…(IN)
    - rank_outs: ì´íƒˆ(OUT)
    - io_cnt: IN/OUT ë™ì¼ ê°œìˆ˜
    """
    # ì˜¤ëŠ˜ TopN ì •ëˆ
    rows = [r for r in rows if isinstance(r.get("rank"), (int, float))]
    rows = sorted(rows, key=lambda r: safe_int(r.get("rank")))
    today_aug = rows[:topN]

    def to_map(lst):
        m = {}
        for it in lst:
            key = str(it.get("key") or it.get("goodsNo") or it.get("product_code") or it.get("url") or it.get("id") or "")
            if key:
                m[key] = it
        return m

    prev_map = to_map(prev_list or [])
    today_map = to_map(today_aug)

    ups, downs = [], []
    for key, today in today_map.items():
        if key in prev_map:
            pr = safe_int(prev_map[key].get("rank"))
            tr = safe_int(today.get("rank"))
            delta = pr - tr  # ì–‘ìˆ˜: ìƒìŠ¹
            base = {
                "key": key,
                "raw_name": today.get("raw_name") or today.get("product_name") or today.get("name") or "",
                "rank": tr,
                "prev_rank": pr,
                "delta": delta,
                "url": today.get("url") or prev_map[key].get("url") or ""
            }
            if delta > 0:
                ups.append(base)
            elif delta < 0:
                downs.append(base)

    prev_keys = set(prev_map.keys())
    today_keys = set(today_map.keys())
    ins_keys = list(today_keys - prev_keys)
    outs_keys = list(prev_keys - today_keys)

    chart_ins = [today_map[k] for k in ins_keys if k in today_map]
    rank_outs = [prev_map[k] for k in outs_keys if k in prev_map]

    # INâ‰¡OUT ê°•ì œ
    io_cnt = min(len(chart_ins), len(rank_outs))
    if len(chart_ins) != len(rank_outs):
        chart_ins = chart_ins[:io_cnt]
        rank_outs = rank_outs[:io_cnt]

    # ì •ë ¬
    ups.sort(key=lambda x: (-x["delta"], x["rank"]))
    downs.sort(key=lambda x: (x["delta"], x["rank"]))
    chart_ins.sort(key=lambda r: safe_int(r.get("rank")))
    rank_outs.sort(key=lambda r: safe_int(r.get("rank")))

    return today_aug, ups, downs, chart_ins, rank_outs, io_cnt

# -----------------------------
# CSV ì €ì¥ & êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
# -----------------------------
def save_csv(rows: List[Dict[str, Any]], path: str):
    ensure_dir(path)
    if not rows:
        # ìµœì†Œ í—¤ë” ë³´ì¡´
        headers = ["key", "raw_name", "rank", "url", "brand", "price", "orig_price", "discount_percent"]
        with open(path, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=headers)
            writer.writeheader()
        return

    headers = sorted({k for r in rows for k in r.keys()})
    with open(path, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        for r in rows:
            writer.writerow(r)

def upload_to_gdrive(file_path: str, folder_id: str = GDRIVE_FOLDER_ID) -> Optional[str]:
    """
    êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ.
    - google-api-python-client ì‚¬ìš© (ëŸ°ë„ˆì— ì¸ì¦ ì„¸íŒ… í•„ìš”)
    - ì„±ê³µ ì‹œ file_id ë°˜í™˜
    """
    if not folder_id:
        print("[ê²½ê³ ] GDRIVE_FOLDER_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœ€.")
        return None
    try:
        from google.oauth2.service_account import Credentials
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        scopes = ["https://www.googleapis.com/auth/drive.file"]
        creds = None

        # ë°©ë²•1: ëŸ°ë„ˆì˜ ADC(Application Default Credentials)
        # ë°©ë²•2: ì„œë¹„ìŠ¤ê³„ì • JSON ê²½ë¡œ ì œê³µ
        sa_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "")
        if sa_path and os.path.exists(sa_path):
            creds = Credentials.from_service_account_file(sa_path, scopes=scopes)
        else:
            # ADC ì‹œë„
            from google.auth import default
            creds, _ = default(scopes=scopes)

        service = build("drive", "v3", credentials=creds)

        file_metadata = {"name": os.path.basename(file_path), "parents": [folder_id]}
        media = MediaFileUpload(file_path, resumable=True)
        file = service.files().create(body=file_metadata, media_body=media, fields="id").execute()
        fid = file.get("id")
        print(f"[Drive] ì—…ë¡œë“œ ì„±ê³µ: {os.path.basename(file_path)} (id={fid})")
        return fid
    except Exception as e:
        print("[Drive] ì—…ë¡œë“œ ì‹¤íŒ¨:", e)
        traceback.print_exc()
        return None

# -----------------------------
# ìŠ¬ë™
# -----------------------------
def post_to_slack(text: str):
    if not SLACK_WEBHOOK_URL:
        print("[ê²½ê³ ] SLACK_WEBHOOK_URL ë¯¸ì„¤ì • â†’ ìŠ¬ë™ ì „ì†¡ ìƒëµ")
        return
    try:
        import requests
        res = requests.post(SLACK_WEBHOOK_URL, json={"text": text}, timeout=15)
        res.raise_for_status()
    except Exception as e:
        print("[ìŠ¬ë™] ì „ì†¡ ì‹¤íŒ¨:", e)

def build_slack_inout_line(io_cnt: int) -> str:
    """
    ìš”êµ¬ í¬ë§·:
    :ì–‘ë°©í–¥_í™”ì‚´í‘œ: ë­í¬ ì¸&ì•„ì›ƒ
    **42ê°œì˜ ì œí’ˆì´ ì¸&ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤.**
    """
    lines = []
    lines.append(":ì–‘ë°©í–¥_í™”ì‚´í‘œ: ë­í¬ ì¸&ì•„ì›ƒ")
    lines.append(f"**{io_cnt}ê°œì˜ ì œí’ˆì´ ì¸&ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤.**")
    return "\n".join(lines)

def build_slack_message(today_aug: List[Dict[str, Any]],
                        ups: List[Dict[str, Any]],
                        downs: List[Dict[str, Any]],
                        chart_ins: List[Dict[str, Any]],
                        rank_outs: List[Dict[str, Any]],
                        io_cnt: int) -> str:
    # ìµœì†Œ ì„¹ì…˜: ì œëª© + IN&OUT í•œ ì¤„ ìš”ì•½ (ìš”ì²­ ë°˜ì˜)
    title = f"ğŸ“Š {SITE_NAME} Top{TOPN} ({kst_today_str('%Y-%m-%d')})"
    msg = [f"*{title}*"]
    msg.append(build_slack_inout_line(io_cnt))
    # í•„ìš” ì‹œ ìƒì„¸ë¥¼ ì¶”ê°€(ì„ íƒ) â€” ê·œì¹™ìƒ í•œ ì¤„ ìš”ì•½ì€ í•„ìˆ˜ë¡œ ì´ë¯¸ í¬í•¨ë¨.
    return "\n".join(msg)

# -----------------------------
# ë©”ì¸
# -----------------------------
def main():
    print("ìˆ˜ì§‘ ì‹œì‘:", f"https://www.{SITE_NAME}.co.kr/")

    # 1) ì˜¤ëŠ˜ 1í˜ì´ì§€ ìˆ˜ì§‘(ê¸°ì¡´ ë¡œì§ í˜¸ì¶œ)
    base_rows = fetch_next_page(page=1) or []
    print(f"[ìˆ˜ì§‘ 1p] {len(base_rows)}ê°œ")

    # 2) TopN=200 ë³´ì¥(ì¶”ê°€ í˜ì´ì§€ ìë™ ì¬ì‹œë„)
    rows = ensure_topN(base_rows, topN=TOPN, site_name=SITE_NAME, max_retry=3, fetch_fn=fetch_next_page)
    print(f"[ìˆ˜ì§‘ ì™„ë£Œ] {len(rows)}ê°œ (ìš”êµ¬: {TOPN})")

    # 3) ì €ì¥ íŒŒì¼ëª… (KST)
    date_tag = datetime.now(KST).strftime("%Y-%m-%d")
    out_dir  = os.getenv("OUT_DIR", "out")
    out_csv  = os.path.join(out_dir, f"{SITE_NAME}_ë·°í‹°ìœ„ìƒ_ì¼ê°„_{date_tag}.csv")

    # 4) ì „ì¼ CSV ë¡œë”© (ê°™ì€ ë””ë ‰í† ë¦¬ ê¸°ì¤€ ì „ì¼ íŒŒì¼ ì¶”ì •)
    prev_date_tag = (datetime.now(KST) - timedelta(days=1)).strftime("%Y-%m-%d")
    prev_csv = os.path.join(out_dir, f"{SITE_NAME}_ë·°í‹°ìœ„ìƒ_ì¼ê°„_{prev_date_tag}.csv")
    prev_list = load_prev_list(prev_csv)
    print(f"[ì „ì¼ ë¡œë”©] {len(prev_list)}ê°œ")

    # 5) ë¶„ì„(!!! ë°˜í™˜ 6ê°œ ê³ ì • !!!)  â† ê¸°ì¡´ ì˜¤ë¥˜ ì§€ì 
    today_aug, ups, downs, chart_ins, rank_outs, io_cnt = analyze_trends(rows, prev_list, topN=TOPN)

    # 6) CSV ì €ì¥
    save_csv(today_aug, out_csv)
    print("[-] CSV ì €ì¥:", out_csv)

    # 7) êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
    file_id = upload_to_gdrive(out_csv, folder_id=GDRIVE_FOLDER_ID)

    # 8) ìŠ¬ë™ ì „ì†¡ (í•„ìš”ì‹œ)
    slack_text = build_slack_message(today_aug, ups, downs, chart_ins, rank_outs, io_cnt)
    post_to_slack(slack_text)

    # 9) ìš”ì•½ ë¡œê·¸
    print(f"[ìš”ì•½] ìƒìŠ¹ {len(ups)} / í•˜ë½ {len(downs)} / IN {io_cnt} / OUT {io_cnt}")
    if file_id:
        print(f"[Drive] file_id={file_id}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        # ì—…ë¡œë“œê°€ ì´ë¯¸ ì„±ê³µí–ˆë”ë¼ë„ 'ì „ì²´ ì‘ì—… ì‹¤íŒ¨'ê°€ ë˜ì§€ ì•Šë„ë¡ ê°€ë…ì„± ì¢‹ì€ ë©”ì‹œì§€ í›„ ì¢…ë£Œì½”ë“œ 1
        print("ì—ëŸ¬:", e)
        traceback.print_exc()
        sys.exit(1)
