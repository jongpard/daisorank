# app.py ‚Äî DaisoMall Î∑∞Ìã∞/ÏúÑÏÉù 'ÏùºÍ∞Ñ' Îû≠ÌÇπ ÏàòÏßë (ÏïàÏ†ïÌôîÌåê)
# - Ïπ¥ÌÖåÍ≥†Î¶¨/Ï†ïÎ†¨ Í∞ïÏ†ú + Í∞ÄÏãúÏÑ±/Ïò§Î≤ÑÎ†àÏù¥ Ïù¥Ïäà Ìï¥Í≤∞Ïö© ÌïòÎìú ÌÅ¥Î¶≠
# - Î¨¥Ìïú Ïä§ÌÅ¨Î°§ ÏïàÏ†ïÌôî
# - JS Ïª®ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú (Ïó¨Îü¨ ÏÖÄÎ†âÌÑ∞ ÎèôÏãú ÎåÄÏùë)
# - BEST Ï†úÍ±∞, Í¥ëÍ≥†/ÎπàÏπ¥Îìú/Ï§ëÎ≥µ Ï†úÍ±∞
# - CSV Ï†ÄÏû•, (ÏÑ†ÌÉù) Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÏóÖÎ°úÎìú, Ïä¨Îûô ÏïåÎ¶º(Ïò¨ÏòÅ Ìè¨Îß∑)

import os, re, csv, time, json
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional, Union
from urllib.parse import urljoin

import requests
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout, Page, Locator

# ====== ÏÑ§Ï†ï ======
RANK_URL = "https://www.daisomall.co.kr/ds/rank/C105"
MAX_ITEMS = int(os.getenv("MAX_ITEMS", "200"))  # 100~200 Í∂åÏû•
SCROLL_PAUSE = 0.6
SCROLL_STABLE_ROUNDS = 4
SCROLL_MAX_ROUNDS = 80

SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL", "")
# Google Drive (ÏÑ†ÌÉù)
GDRIVE_FOLDER_ID = os.getenv("GDRIVE_FOLDER_ID", "")
GOOGLE_CLIENT_ID = os.getenv("GOOGLE_CLIENT_ID", "")
GOOGLE_CLIENT_SECRET = os.getenv("GOOGLE_CLIENT_SECRET", "")
GOOGLE_REFRESH_TOKEN = os.getenv("GOOGLE_REFRESH_TOKEN", "")

KST = timezone(timedelta(hours=9))


# ====== Ïú†Ìã∏ ======
def today_str() -> str:
    return datetime.now(KST).strftime("%Y-%m-%d")


def yday_str() -> str:
    return (datetime.now(KST) - timedelta(days=1)).strftime("%Y-%m-%d")


def strip_best(name: str) -> str:
    if not name:
        return ""
    name = re.sub(r"^\s*BEST\s*[\|\-:\u00A0]*", "", name, flags=re.I)
    name = re.sub(r"\s*\bBEST\b\s*", " ", name, flags=re.I)
    return re.sub(r"\s+", " ", name).strip()


def _to_locator(page: Page, target: Union[str, Locator]) -> Locator:
    return target if isinstance(target, Locator) else page.locator(target)


def close_overlays(page: Page):
    # ÌùîÌïú Î†àÏù¥Ïñ¥/Î∞∞ÎÑà Îã´Í∏∞ (ÏûàÏùÑ ÎïåÎßå ÏãúÎèÑ)
    candidates = [
        ".layer-popup .btn-close", ".modal .btn-close", ".popup .btn-close",
        ".layer-popup .close", ".modal .close", ".popup .close",
        ".btn-x", ".btn-close, button[aria-label='Îã´Í∏∞']"
    ]
    for sel in candidates:
        try:
            if page.locator(sel).count() > 0:
                page.locator(sel).first.click(timeout=1000)
                page.wait_for_timeout(200)
        except Exception:
            pass


def click_hard(page: Page, target: Union[str, Locator], name_for_log: str = ""):
    """Í∞ÄÏãúÏÑ±/Ïò§Î≤ÑÎ†àÏù¥ Ïù¥ÏäàÎ•º Îö´Îäî Îã§Îã®Í≥Ñ ÌÅ¥Î¶≠"""
    loc = _to_locator(page, target)
    # Îã®Í≥Ñ 0: Ï°¥Ïû¨ ÎåÄÍ∏∞
    try:
        loc.first.wait_for(state="attached", timeout=3000)
    except Exception:
        raise RuntimeError(f"[click_hard] ÎåÄÏÉÅ ÎØ∏Ï°¥Ïû¨: {name_for_log}")

    # Îã®Í≥Ñ 1: Ï†ïÏÉÅ ÌÅ¥Î¶≠
    for _ in range(2):
        try:
            loc.first.click(timeout=1200)
            return
        except Exception:
            pass

    # Îã®Í≥Ñ 2: Ïä§ÌÅ¨Î°§ Ï§ëÏïô -> ÌÅ¥Î¶≠
    try:
        loc.first.scroll_into_view_if_needed(timeout=1000)
        page.wait_for_timeout(150)
        loc.first.click(timeout=1200)
        return
    except Exception:
        pass

    # Îã®Í≥Ñ 3: JS Í∞ïÏ†ú ÌÅ¥Î¶≠ (el.click())
    try:
        loc.first.evaluate("(el) => { el.click(); }")
        return
    except Exception:
        pass

    # Îã®Í≥Ñ 4: PointerEvent ÎîîÏä§Ìå®Ïπò
    try:
        loc.first.evaluate("""(el) => {
            const ev = new PointerEvent('click', {bubbles:true, cancelable:true});
            el.dispatchEvent(ev);
        }""")
        return
    except Exception:
        pass

    # Îã®Í≥Ñ 5: ÎßàÏö∞Ïä§ Ï¢åÌëú ÌÅ¥Î¶≠
    try:
        box = loc.first.bounding_box()
        if box:
            page.mouse.move(box["x"] + box["width"]/2, box["y"] + box["height"]/2)
            page.mouse.click(box["x"] + box["width"]/2, box["y"] + box["height"]/2)
            return
    except Exception:
        pass

    # Îã®Í≥Ñ 6: ÏÉÅÎã® Í≥†Ï†ï Ìó§Îçî/Î∞∞ÎÑà Î¨¥Î†•Ìôî ÌõÑ Ïû¨ÏãúÎèÑ
    try:
        page.evaluate("""
            () => {
              const hide = sel => {
                const el = document.querySelector(sel);
                if (el) { el.style.pointerEvents = 'none'; el.style.zIndex = '0'; }
              };
              hide('header'); hide('.header'); hide('#header');
              hide('.fixed-top'); hide('.floating'); hide('.top-banner');
            }
        """)
        loc.first.scroll_into_view_if_needed(timeout=800)
        page.wait_for_timeout(120)
        loc.first.click(timeout=1200)
        return
    except Exception:
        pass

    raise RuntimeError(f"[click_hard] ÌÅ¥Î¶≠ Ïã§Ìå®: {name_for_log}")


# ====== Playwright (Ïπ¥ÌÖåÍ≥†Î¶¨/Ï†ïÎ†¨ Í≥†Ï†ï + Ïä§ÌÅ¨Î°§ + Ï∂îÏ∂ú) ======
def select_beauty_daily(page: Page):
    close_overlays(page)

    # 1) Ïπ¥ÌÖåÍ≥†Î¶¨ 'Î∑∞Ìã∞/ÏúÑÏÉù'
    # value ÏãúÎèÑ ‚Üí ÌÖçÏä§Ìä∏ ÏãúÎèÑ ‚Üí JS Í∞ïÏ†ú
    try:
        if page.locator('.prod-category .cate-btn[value="CTGR_00014"]').count() > 0:
            click_hard(page, '.prod-category .cate-btn[value="CTGR_00014"]', "Î∑∞Ìã∞/ÏúÑÏÉù(value)")
        else:
            click_hard(page, page.get_by_role("button", name=re.compile("Î∑∞Ìã∞\\/?ÏúÑÏÉù")), "Î∑∞Ìã∞/ÏúÑÏÉù(text)")
    except Exception:
        # JS ÏµúÌõÑ ÏàòÎã®
        page.evaluate("""
            () => {
              const byVal = document.querySelector('.prod-category .cate-btn[value="CTGR_00014"]');
              if (byVal) byVal.click();
              else {
                const btns = [...document.querySelectorAll('.prod-category .cate-btn, .prod-category *')];
                const t = btns.find(b => /Î∑∞Ìã∞\\/?ÏúÑÏÉù/.test((b.textContent||"").trim()));
                if (t) t.click();
              }
            }
        """)
    page.wait_for_load_state("networkidle")
    page.wait_for_timeout(300)

    # Ïã§Ï†ú ÏÑ†ÌÉù Í≤ÄÏ¶ù
    selected_txt = page.evaluate("""
      () => {
        const act = document.querySelector('.prod-category .cate-btn.is-active, .prod-category .cate-btn.active');
        return (act?.textContent || '').trim();
      }
    """)
    if not (selected_txt and ("Î∑∞Ìã∞" in selected_txt or "ÏúÑÏÉù" in selected_txt)):
        # Ìïú Î≤à Îçî ÏãúÎèÑ
        try:
            click_hard(page, '.prod-category .cate-btn[value="CTGR_00014"]', "Î∑∞Ìã∞/ÏúÑÏÉù Ïû¨ÏãúÎèÑ")
            page.wait_for_timeout(200)
        except Exception:
            pass

    # 2) Ï†ïÎ†¨ 'ÏùºÍ∞Ñ' -> input[value=2] / ÌÖçÏä§Ìä∏ 'ÏùºÍ∞Ñ'
    chosen = False
    if page.locator('.ipt-sorting input[value="2"]').count() > 0:
        try:
            click_hard(page, '.ipt-sorting input[value="2"]', "ÏùºÍ∞Ñ(value)")
            chosen = True
        except Exception:
            pass
    if not chosen:
        try:
            click_hard(page, page.get_by_role("button", name=re.compile("ÏùºÍ∞Ñ")), "ÏùºÍ∞Ñ(text)")
            chosen = True
        except Exception:
            # JS ÏµúÌõÑ ÏàòÎã®
            page.evaluate("""
                () => {
                  const r = document.querySelector('.ipt-sorting input[value="2"]');
                  if (r) r.click();
                  const btns = [...document.querySelectorAll('.ipt-sorting *')];
                  const t = btns.find(b => /ÏùºÍ∞Ñ/.test((b.textContent||"")));
                  if (t) t.click();
                }
            """)

    page.wait_for_load_state("networkidle")
    page.wait_for_timeout(400)


def infinite_scroll(page: Page):
    prev = 0
    stable = 0
    for _ in range(SCROLL_MAX_ROUNDS):
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        page.wait_for_load_state("networkidle")
        page.wait_for_timeout(int(SCROLL_PAUSE * 1000))
        cnt = page.evaluate("""
            () => document.querySelectorAll('.goods-list .goods-unit, .goods-list .goods-item, .goods-list li.goods, .goods-unit-v2').length
        """)
        if cnt >= MAX_ITEMS:
            break
        if cnt == prev:
            stable += 1
            if stable >= SCROLL_STABLE_ROUNDS:
                break
        else:
            stable = 0
            prev = cnt


def collect_items(page: Page) -> List[Dict]:
    data = page.evaluate(
        """
        () => {
          const qs = sel => [...document.querySelectorAll(sel)];
          const units = qs('.goods-list .goods-unit, .goods-list .goods-item, .goods-list li.goods, .goods-unit-v2');
          const seen = new Set();
          const items = [];
          for (const el of units) {
            // Ïù¥Î¶Ñ
            const nameEl = el.querySelector('.goods-detail .tit a, .goods-detail .tit, .tit a, .tit, .name, .goods-name');
            let name = (nameEl?.textContent || '').trim();
            if (!name) continue;
            // Í∞ÄÍ≤©
            const priceEl = el.querySelector('.goods-detail .goods-price .value, .price .num, .sale-price .num, .sale .price, .goods-price .num');
            let priceTxt = (priceEl?.textContent || '').replace(/[^0-9]/g, '');
            if (!priceTxt) continue;
            const price = parseInt(priceTxt, 10);
            if (!price || price <= 0) continue;
            // URL
            let href = null;
            const a = el.querySelector('a[href*="/goods/"], a[href*="/product/"], a.goods-link, .goods-detail a');
            if (a && a.href) href = a.href;
            if (!href) continue;
            if (seen.has(href)) continue;
            seen.add(href);
            items.push({ name, price, url: href });
          }
          return items;
        }
        """
    )
    cleaned = []
    for it in data:
        nm = strip_best(it["name"])
        if not nm:
            continue
        cleaned.append({"name": nm, "price": it["price"], "url": it["url"]})
    for i, it in enumerate(cleaned, 1):
        it["rank"] = i
    return cleaned


def fetch_products() -> List[Dict]:
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            viewport={"width": 1360, "height": 900},
            user_agent=("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/123.0.0.0 Safari/537.36"),
        )
        page = context.new_page()
        page.goto(RANK_URL, wait_until="domcontentloaded", timeout=45_000)

        # Ï£ºÏöî Î∏îÎ°ù ÎåÄÍ∏∞
        try:
            page.wait_for_selector(".prod-category", timeout=15_000)
        except PWTimeout:
            pass

        select_beauty_daily(page)

        # Ï≤´ Ïπ¥Îìú ÎåÄÍ∏∞
        try:
            page.wait_for_selector(".goods-list .goods-unit, .goods-list .goods-item, .goods-list li.goods, .goods-unit-v2", timeout=20_000)
        except PWTimeout:
            pass

        infinite_scroll(page)
        items = collect_items(page)

        context.close()
        browser.close()
        return items


# ====== CSV Ï†ÄÏû• ======
def save_csv(rows: List[Dict]) -> str:
    date_str = today_str()
    os.makedirs("data", exist_ok=True)
    path = os.path.join("data", f"Îã§Ïù¥ÏÜåÎ™∞_Î∑∞Ìã∞ÏúÑÏÉù_ÏùºÍ∞Ñ_{date_str}.csv")
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["date", "rank", "name", "price", "url"])
        for r in rows:
            w.writerow([date_str, r["rank"], r["name"], r["price"], r["url"]])
    return path


# ====== Î≥ÄÌôî Í∞êÏßÄ ======
def load_prev_map() -> Dict[str, int]:
    prev = {}
    fn = os.path.join("data", f"Îã§Ïù¥ÏÜåÎ™∞_Î∑∞Ìã∞ÏúÑÏÉù_ÏùºÍ∞Ñ_{yday_str()}.csv")
    if not os.path.exists(fn):
        return prev
    with open(fn, newline="", encoding="utf-8") as f:
        for row in csv.DictReader(f):
            try:
                prev[row["url"]] = int(row["rank"])
            except Exception:
                pass
    return prev


def build_diff(cur: List[Dict], prev_map: Dict[str, int]):
    ups, downs, newin, out = [], [], [], []
    cur_urls = [x["url"] for x in cur]
    for it in cur:
        u, r = it["url"], it["rank"]
        pr = prev_map.get(u)
        if pr is None:
            if r <= 30:
                newin.append((r, it["name"]))
        else:
            d = pr - r
            if d >= 20:
                ups.append((r, it["name"], f"{pr}‚Üí{r}"))
            elif d <= -20:
                downs.append((r, it["name"], f"{pr}‚Üí{r}"))
    for u, pr in prev_map.items():
        if u not in cur_urls and pr <= 30:
            out.append(pr)
    return ups[:5], newin[:5], downs[:5], out


# ====== Slack ======
def post_slack(rows: List[Dict]):
    if not SLACK_WEBHOOK:
        return
    lines = []
    lines.append(f"*Îã§Ïù¥ÏÜåÎ™∞ Î∑∞Ìã∞/ÏúÑÏÉù ÏùºÍ∞Ñ Îû≠ÌÇπ ‚Äî {today_str()}*")
    lines.append("")
    lines.append("*TOP 10*")
    for it in rows[:10]:
        lines.append(f"{it['rank']}. <{it['url']}|{it['name']}> ‚Äî {it['price']:,}Ïõê")

    prev_map = load_prev_map()
    ups, newin, downs, out = build_diff(rows, prev_map)

    lines.append("\nüî• *Í∏âÏÉÅÏäπ*")
    if ups:
        for r, name, mv in ups:
            lines.append(f"- {name} ({mv})")
    else:
        lines.append("- Ìï¥Îãπ ÏóÜÏùå")

    lines.append("\nüÜï *Îâ¥Îû≠Ïª§*")
    if newin:
        for r, name in newin:
            lines.append(f"- {name} NEW ‚Üí {r}ÏúÑ")
    else:
        lines.append("- Ìï¥Îãπ ÏóÜÏùå")

    lines.append("\nüìâ *Í∏âÌïòÎùΩ*")
    if downs:
        for r, name, mv in downs:
            lines.append(f"- {name} ({mv})")
    else:
        lines.append("- Ìï¥Îãπ ÏóÜÏùå")

    lines.append("\nüîó *ÎßÅÌÅ¨ Ïù∏&ÏïÑÏõÉ*")
    if out:
        lines.append(f"{len(out)}Í∞úÏùò Ï†úÌíàÏù¥ Ïù∏&ÏïÑÏõÉ ÎêòÏóàÏäµÎãàÎã§.")
    else:
        lines.append("0Í∞úÏùò Ï†úÌíàÏù¥ Ïù∏&ÏïÑÏõÉ ÎêòÏóàÏäµÎãàÎã§.")

    try:
        requests.post(SLACK_WEBHOOK, json={"text": "\n".join(lines)}, timeout=10).raise_for_status()
    except Exception as e:
        print("[Slack] Ï†ÑÏÜ° Ïã§Ìå®:", e)


# ====== Google Drive (ÏÑ†ÌÉù) ======
def upload_to_drive(path: str) -> Optional[str]:
    if not (GDRIVE_FOLDER_ID and GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET and GOOGLE_REFRESH_TOKEN):
        return None
    try:
        tok = requests.post(
            "https://oauth2.googleapis.com/token",
            data={
                "client_id": GOOGLE_CLIENT_ID,
                "client_secret": GOOGLE_CLIENT_SECRET,
                "refresh_token": GOOGLE_REFRESH_TOKEN,
                "grant_type": "refresh_token",
            },
            timeout=15,
        )
        tok.raise_for_status()
        access_token = tok.json()["access_token"]

        meta = {"name": os.path.basename(path), "parents": [GDRIVE_FOLDER_ID]}
        files = {
            "metadata": ("metadata", json.dumps(meta), "application/json"),
            "file": (os.path.basename(path), open(path, "rb"), "text/csv"),
        }
        up = requests.post(
            "https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart",
            headers={"Authorization": f"Bearer {access_token}"},
            files=files,
            timeout=60,
        )
        up.raise_for_status()
        return up.json().get("id")
    except Exception as e:
        print("[Drive] ÏóÖÎ°úÎìú Ïã§Ìå®:", e)
        return None


# ====== main ======
def main():
    print("ÏàòÏßë ÏãúÏûë:", RANK_URL)
    t0 = time.time()
    rows = fetch_products()
    print("[ÏàòÏßë ÏôÑÎ£å] Í∞úÏàò:", len(rows))
    if len(rows) < 10:
        raise RuntimeError("Ïú†Ìö® ÏÉÅÌíà Ïπ¥ÎìúÍ∞Ä ÎÑàÎ¨¥ Ï†ÅÍ≤å ÏàòÏßëÎêòÏóàÏäµÎãàÎã§. ÏÖÄÎ†âÌÑ∞/Î†åÎçîÎßÅ Ï†êÍ≤Ä ÌïÑÏöî")

    csv_path = save_csv(rows)
    upload_to_drive(csv_path)
    post_slack(rows)

    print("Î°úÏª¨ Ï†ÄÏû•:", csv_path)
    print("Ï¥ù", len(rows), "Í±¥, Í≤ΩÍ≥º:", f"{time.time()-t0:.1f}s")


if __name__ == "__main__":
    main()
