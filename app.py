# -*- coding: utf-8 -*-
"""
ë‹¤ì´ì†Œëª° ë·°í‹°/ìœ„ìƒ ì¼ê°„ ë­í‚¹ í¬ë¡¤ëŸ¬
- ìˆ˜ì§‘ URL: https://www.daisomall.co.kr/ds/rank/C105
- ìˆ˜ì§‘ í›„ CSV ì €ì¥: data/ë‹¤ì´ì†Œëª°_ë·°í‹°ìœ„ìƒ_ì¼ê°„_YYYY-MM-DD.csv (KST)
- êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ (ë¦¬í¬ ì‹œí¬ë¦¿ ì‚¬ìš©)
- ìŠ¬ë™ í¬ë§·: (ì˜¬ë¦¬ë¸Œì˜ ë²„ì „ê³¼ ë™ì¼)
    * ì œëª©/ì†Œì œëª© **êµµê²Œ**
    * TOP 10 â†’ ê¸‰ìƒìŠ¹(ìƒìœ„3) â†’ ë‰´ë­ì»¤(ìƒìœ„3 ê¶Œì¥) â†’ ê¸‰í•˜ë½(ìƒìœ„5) â†’ ë­í¬ ì¸&ì•„ì›ƒ(ê°œìˆ˜ë§Œ)
    * TOP10 ë¼ì¸: "1. <ì œí’ˆëª… ë§í¬> â€” 2,000ì›"
    * ê¸‰ìƒìŠ¹/ë‰´ë­ì»¤/ê¸‰í•˜ë½ ë¼ì¸:
        - ì œí’ˆëª… 71ìœ„ â†’ 7ìœ„ (â†‘64)
        - ì œí’ˆëª… NEW â†’ 19ìœ„
        - ì œí’ˆëª… 23ìœ„ â†’ OUT
    * 'BEST' í‘œì‹œëŠ” ëª¨ë‘ ì œê±°
- ì „ì¼ CSVì™€ ë¹„êµí•´ ë³€ë™ ê³„ì‚°(Top30 ê¸°ì¤€)
- Playwright â†’ ì‹¤íŒ¨ ì‹œ Requests(ì •ì  íŒŒì‹±) í´ë°±
"""

import os, re, io, sys, json, time, math, csv, pathlib, traceback, datetime as dt
from typing import List, Dict, Tuple, Optional

import pytz
import requests
from bs4 import BeautifulSoup

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaInMemoryUpload

# ---- í™˜ê²½ì„¤ì • --------------------------------------------------------------

BASE_URL = "https://www.daisomall.co.kr"
RANK_URL = f"{BASE_URL}/ds/rank/C105"   # ë·°í‹°/ìœ„ìƒ ì¼ê°„

DATA_DIR = pathlib.Path("data")
DEBUG_DIR = pathlib.Path("data/debug")
DATA_DIR.mkdir(parents=True, exist_ok=True)
DEBUG_DIR.mkdir(parents=True, exist_ok=True)

KST = pytz.timezone("Asia/Seoul")

SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL", "").strip()

GDRIVE_CLIENT_ID = os.environ.get("GOOGLE_CLIENT_ID", "").strip()
GDRIVE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET", "").strip()
GDRIVE_REFRESH_TOKEN = os.environ.get("GOOGLE_REFRESH_TOKEN", "").strip()
GDRIVE_FOLDER_ID = os.environ.get("GDRIVE_FOLDER_ID", "").strip()

# ---- ê³µí†µ ìœ í‹¸ -------------------------------------------------------------

def today_ymd_kst() -> str:
    return dt.datetime.now(KST).strftime("%Y-%m-%d")

def ymd(d: dt.date) -> str:
    return d.strftime("%Y-%m-%d")

def slack_escape(text: str) -> str:
    # ìŠ¬ë™ ë§í¬ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œë  ìˆ˜ ìˆëŠ” ê¸°í˜¸ ì–´ëŠì •ë„ ë°©ì–´
    return text.replace("&", "&amp;").replace("<", "ã€ˆ").replace(">", "ã€‰")

def to_int(s: str) -> Optional[int]:
    try:
        return int(re.sub(r"[^\d]", "", s))
    except:
        return None

def format_won(num: Optional[int]) -> str:
    if num is None: return "â‚©0"
    return f"{num:,}ì›"

def load_csv(path: pathlib.Path) -> List[Dict]:
    if not path.exists(): return []
    out = []
    with path.open("r", newline="", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            # ì•ˆì „ ë³€í™˜
            row["rank"] = int(row.get("rank", "0") or 0)
            row["price"] = int(row.get("price", "0") or 0)
            out.append(row)
    return out

def save_csv(path: pathlib.Path, rows: List[Dict]):
    cols = ["date","rank","name","price","url"]
    with path.open("w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=cols)
        w.writeheader()
        for r in rows:
            w.writerow({k: r.get(k, "") for k in cols})

# ---- êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ---------------------------------------------------

def gdrive_build():
    if not (GDRIVE_CLIENT_ID and GDRIVE_CLIENT_SECRET and GDRIVE_REFRESH_TOKEN and GDRIVE_FOLDER_ID):
        raise RuntimeError("Google Drive í´ë”/ìê²© ì •ë³´ ë¶€ì¡±. ë¦¬í¬ ì‹œí¬ë¦¿ í™•ì¸ í•„ìš”")
    creds = Credentials(
        None,
        refresh_token=GDRIVE_REFRESH_TOKEN,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=GDRIVE_CLIENT_ID,
        client_secret=GDRIVE_CLIENT_SECRET,
        scopes=["https://www.googleapis.com/auth/drive.file","https://www.googleapis.com/auth/drive"]
    )
    return build("drive", "v3", credentials=creds, cache_discovery=False)

def gdrive_upload_csv(path: pathlib.Path) -> str:
    service = gdrive_build()
    media = MediaInMemoryUpload(path.read_bytes(), mimetype="text/csv", resumable=False)
    body = {"name": path.name, "parents": [GDRIVE_FOLDER_ID]}
    file = service.files().create(body=body, media_body=media, fields="id").execute()
    return file["id"]

# ---- Playwright í¬ë¡¤ëŸ¬ (ê°€ëŠ¥ ì‹œ) --------------------------------------------

def fetch_by_playwright() -> List[Dict]:
    """
    Playwrightë¡œ ìƒí’ˆ ì¹´ë“œ íŒŒì‹±. ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë˜ì ¸ í´ë°±í•˜ë„ë¡ í•¨.
    """
    from playwright.sync_api import sync_playwright

    items: List[Dict] = []
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox"])
        page = browser.new_page(viewport={"width":1280, "height":2200})
        page.goto(RANK_URL, timeout=60_000)
        # íƒ­ 'ì¼ê°„' í´ë¦­ ì•ˆì „ë§ (ì´ë¯¸ ì¼ê°„ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
        try:
            page.get_by_role("tab", name=re.compile("ì¼ê°„")).click(timeout=3_000)
        except Exception:
            pass

        # ì¹´ë“œ ë¡œë“œ ëŒ€ê¸°
        page.wait_for_selector(".goods-unit", timeout=30_000)
        # ìŠ¤í¬ë¦°ìƒ·/HTML ë””ë²„ê·¸ ì €ì¥
        DEBUG_DIR.mkdir(parents=True, exist_ok=True)
        page.screenshot(path=str(DEBUG_DIR / "page_rank.png"), full_page=True)
        (DEBUG_DIR / "page_rank.html").write_text(page.content(), encoding="utf-8")

        # íŒŒì‹±
        html = page.content()
        browser.close()

    return parse_from_html(html)

# ---- Requests í´ë°± ---------------------------------------------------------

def fetch_by_requests() -> List[Dict]:
    r = requests.get(RANK_URL, timeout=30, headers={
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0 Safari/537.36"
    })
    r.raise_for_status()
    html = r.text
    (DEBUG_DIR / "page_rank.html").write_text(html, encoding="utf-8")
    return parse_from_html(html)

# ---- HTML íŒŒì„œ --------------------------------------------------------------

def parse_from_html(html: str) -> List[Dict]:
    """
    ë””ë²„ê·¸ sample ê¸°ì¤€ êµ¬ì¡°:
      .goods-unit
        .ranking-area .rank .num         -> í˜„ì¬ ìˆœìœ„
        .goods-thumb a.goods-link[href]   -> ìƒí’ˆ ë§í¬(/pd/pdr/... ?pdNo=####)
        .goods-detail .goods-price .value -> ê°€ê²© ìˆ«ì
        .goods-detail .tit .best          -> 'BEST' ë¼ë²¨ (ì œê±°)
        .goods-detail .tit (text)         -> ìƒí’ˆëª…
    """
    soup = BeautifulSoup(html, "lxml")
    cards = soup.select(".goods-unit")
    items: List[Dict] = []

    for card in cards:
        num_el = card.select_one(".ranking-area .rank .num")
        if not num_el:
            # ë°°ë„ˆ ë“±ì€ ìŠ¤í‚µ
            continue
        rank = to_int(num_el.get_text(strip=True)) or 0

        link_tag = card.select_one(".goods-thumb a.goods-link")
        url = BASE_URL + link_tag["href"] if link_tag and link_tag.has_attr("href") else RANK_URL

        # ì´ë¦„
        tit = card.select_one(".goods-detail .tit")
        name = ""
        if tit:
            # span.best ì œê±°
            for b in tit.select(".best"):
                b.extract()
            name = " ".join(tit.get_text(" ", strip=True).split())
            # í˜¹ì‹œ ë‚¨ì€ "BEST" ì ‘ë‘ì–´ í…ìŠ¤íŠ¸ ì œê±° (2ì¤‘ ì•ˆì „ë§)
            name = re.sub(r"^\s*BEST\s*", "", name, flags=re.I)

        # ê°€ê²©
        price_el = card.select_one(".goods-detail .goods-price .value")
        price = to_int(price_el.get_text(strip=True)) if price_el else None

        items.append({
            "rank": rank,
            "name": name,
            "price": price or 0,
            "url": url,
        })

    # ìˆœìœ„ ê¸°ì¤€ ì •ë ¬(í˜¹ì‹œ ì„ì—¬ ìˆìœ¼ë©´)
    items = sorted(items, key=lambda x: x["rank"])
    return items

# ---- ë³€ë™ ê³„ì‚° --------------------------------------------------------------

def previous_csv_path(today_path: pathlib.Path) -> Optional[pathlib.Path]:
    # data/ë‹¤ì´ì†Œëª°_ë·°í‹°ìœ„ìƒ_ì¼ê°„_YYYY-MM-DD.csv ì¤‘ ê°€ì¥ ìµœê·¼ ê³¼ê±° íŒŒì¼
    stem = "ë‹¤ì´ì†Œëª°_ë·°í‹°ìœ„ìƒ_ì¼ê°„_"
    candidates = sorted(DATA_DIR.glob(f"{stem}*.csv"))
    prevs = [p for p in candidates if p.name < today_path.name]
    return prevs[-1] if prevs else None

def analyze_changes(today: List[Dict], prev: List[Dict]) -> Dict[str, List[Dict]]:
    """
    Top30 ê¸°ì¤€:
      - ê¸‰ìƒìŠ¹: prevâˆ©today ì¤‘ rank ê°œì„ í­ (prev - curr) ì–‘ìˆ˜ ìƒìœ„ 3
      - ë‰´ë­ì»¤: prev>30 ë˜ëŠ” ë¯¸ë“±ì¥ â†’ today<=30 ìƒìœ„ (ìµœëŒ€ 3)
      - ê¸‰í•˜ë½: prevâˆ©today ì¤‘ rank í•˜ë½í­ (curr - prev) ì–‘ìˆ˜ ìƒìœ„ 5 + ë­í¬ì•„ì›ƒ(prev<=30 & today>30)
      - ì¸&ì•„ì›ƒ: ìœ„ 'ë‰´ë­ì»¤' + 'ë­í¬ì•„ì›ƒ' ê°œìˆ˜ í•© (ì •ìˆ˜)
    """
    N = 30
    prev_map = {normalize_name(r["name"]): r for r in prev}
    today_map = {normalize_name(r["name"]): r for r in today}

    # ê³µí†µ
    rising, falling = [], []
    new_in, out_items = [], []

    for key, t in today_map.items():
        if t["rank"] > N: 
            continue
        p = prev_map.get(key)
        if p:
            delta = p["rank"] - t["rank"]
            if delta > 0:
                rising.append({"name": t["name"], "prev": p["rank"], "curr": t["rank"], "delta": delta, "url": t["url"]})
        else:
            # ë‰´ë­ì»¤
            new_in.append({"name": t["name"], "prev": None, "curr": t["rank"], "url": t["url"]})

    for key, p in prev_map.items():
        if p["rank"] <= N:
            t = today_map.get(key)
            if not t or (t["rank"] > N):
                out_items.append({"name": p["name"], "prev": p["rank"], "curr": None})

    # ê¸‰í•˜ë½(ê³µí†µ ì¡´ì¬ + í•˜ë½í­ í° ìˆœ)
    for key, t in today_map.items():
        p = prev_map.get(key)
        if p:
            delta_down = t["rank"] - p["rank"]
            if delta_down > 0:
                falling.append({"name": t["name"], "prev": p["rank"], "curr": t["rank"], "delta": delta_down, "url": t["url"]})

    rising.sort(key=lambda x: (-x["delta"], x["curr"], x["prev"] or 9999, normalize_name(x["name"])))
    falling.sort(key=lambda x: (-x["delta"], x["prev"], x["curr"] or 9999, normalize_name(x["name"])))
    new_in.sort(key=lambda x: (x["curr"], normalize_name(x["name"])))
    out_items.sort(key=lambda x: (x["prev"], normalize_name(x["name"])))

    return {
        "rising": rising[:3],
        "new_in": new_in[:3],
        "falling": falling[:5],
        "out": out_items,  # ê¸‰í•˜ë½ ì„¹ì…˜ì—ì„œ OUT í•¨ê»˜ í‘œê¸°í•  ë•Œ ì‚¬ìš©
        "inout_count": len(new_in) + len(out_items),
    }

def normalize_name(s: str) -> str:
    # ë¹„êµ ì•ˆì •í™”ë¥¼ ìœ„í•´ ê³µë°±/ëŒ€ì†Œë¬¸ì/íŠ¹ìˆ˜ë¬¸ì ì•½ê°„ ì •ê·œí™” (í•„ìš”ì‹œ í™•ì¥)
    s = re.sub(r"\s+", " ", s or "").strip()
    return s.lower()

# ---- ìŠ¬ë™ ë©”ì‹œì§€ ------------------------------------------------------------

def post_to_slack(text: str):
    if not SLACK_WEBHOOK_URL:
        print("[Slack] ë¯¸ì„¤ì •. ë©”ì‹œì§€ ìƒëµ")
        return
    try:
        requests.post(SLACK_WEBHOOK_URL, json={"text": text}, timeout=10)
        print("Slack ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"[Slack] ì „ì†¡ ì‹¤íŒ¨: {e}")

def make_slack_message(today_rows: List[Dict], prev_rows: List[Dict], change: Dict, csv_path: pathlib.Path, drive_file_id: Optional[str]) -> str:
    today_kst = today_ymd_kst()
    lines = []

    lines.append(f"*ë‹¤ì´ì†Œëª° ë·°í‹°/ìœ„ìƒ ì¼ê°„ â€” {today_kst}*")
    lines.append("")
    # TOP 10
    lines.append("*TOP 10*")
    top10 = [r for r in today_rows if r["rank"] <= 10]
    for r in top10:
        # í•˜ì´í¼ë§í¬
        nm = slack_escape(r["name"])
        url = r["url"]
        price = format_won(r["price"])
        lines.append(f"{r['rank']}. <{url}|{nm}> â€” {price}")
    lines.append("")

    # ê¸‰ìƒìŠ¹
    lines.append("ğŸ”¥ *ê¸‰ìƒìŠ¹*")
    if change["rising"]:
        for r in change["rising"]:
            nm = slack_escape(r["name"])
            lines.append(f"- {nm} {r['prev']}ìœ„ â†’ {r['curr']}ìœ„ (â†‘{r['delta']})")
    else:
        lines.append("- í•´ë‹¹ ì—†ìŒ")
    lines.append("")

    # ë‰´ë­ì»¤
    lines.append("ğŸ†• *ë‰´ë­ì»¤*")
    if change["new_in"]:
        for r in change["new_in"]:
            nm = slack_escape(r["name"])
            lines.append(f"- {nm} NEW â†’ {r['curr']}ìœ„")
    else:
        lines.append("- í•´ë‹¹ ì—†ìŒ")
    lines.append("")

    # ê¸‰í•˜ë½ + OUT
    lines.append("ğŸ“‰ *ê¸‰í•˜ë½*")
    had_any = False
    for r in change["falling"]:
        had_any = True
        nm = slack_escape(r["name"])
        lines.append(f"- {nm} {r['prev']}ìœ„ â†’ {r['curr']}ìœ„ (â†“{r['delta']})")
    # OUT í‘œê¸° (Top30 â†’ ì˜¤ëŠ˜ Out)
    outs = [o for o in change["out"] if (o["prev"] and o["prev"] <= 30)]
    for o in outs:
        had_any = True
        nm = slack_escape(o["name"])
        lines.append(f"- {nm} {o['prev']}ìœ„ â†’ OUT")
    if not had_any:
        lines.append("- í•´ë‹¹ ì—†ìŒ")
    lines.append("")

    # ì¸&ì•„ì›ƒ ê°œìˆ˜
    lines.append("ğŸ” *ë­í¬ ì¸&ì•„ì›ƒ*")
    lines.append(f"{change['inout_count']}ê°œì˜ ì œí’ˆì´ ì¸&ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    lines.append("")

    # ì°¸ê³  ì •ë³´(íŒŒì¼)
    tail = [f"CSV: `{csv_path.name}`"]
    if drive_file_id:
        tail.append(f"Drive íŒŒì¼ ID: `{drive_file_id}`")
    lines.append("_" + "  â€¢  ".join(tail) + "_")

    return "\n".join(lines)

# ---- ë©”ì¸ --------------------------------------------------------------

def main():
    t0 = time.time()
    print(f"ìˆ˜ì§‘ ì‹œì‘: {RANK_URL}")

    # 1) ìˆ˜ì§‘
    items: List[Dict] = []
    try:
        items = fetch_by_playwright()
        print("[Playwright] ì •ìƒ ìˆ˜ì§‘")
    except Exception as e:
        print("[Playwright] ì‹¤íŒ¨ â†’ í´ë°± ì§„ì…")
        print(str(e))
        items = fetch_by_requests()

    # ìµœì†Œ ê±´ìˆ˜ ë°©ì–´ (ë””ë²„ê·¸ HTMLë„ ì´ë¯¸ ì €ì¥ë¨)
    print(f"ìˆ˜ì§‘ ì™„ë£Œ: {len(items)}")
    if len(items) < 10:
        raise RuntimeError("ì œí’ˆ ì¹´ë“œê°€ ë„ˆë¬´ ì ê²Œ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì…€ë ‰í„°/ë Œë”ë§ ì ê²€ í•„ìš”")

    # 2) CSV ì €ì¥
    today = today_ymd_kst()
    csv_path = DATA_DIR / f"ë‹¤ì´ì†Œëª°_ë·°í‹°ìœ„ìƒ_ì¼ê°„_{today}.csv"
    rows = []
    for r in items:
        rows.append({
            "date": today,
            "rank": r["rank"],
            "name": r["name"],                 # 'BEST' ì œê±°ëœ ìƒíƒœ
            "price": int(r["price"] or 0),
            "url": r["url"],
        })
    save_csv(csv_path, rows)

    # 3) ì „ì¼ê³¼ ë¹„êµ
    prev_path = previous_csv_path(csv_path)
    prev_rows = load_csv(prev_path) if prev_path else []
    change = analyze_changes(rows, prev_rows)

    # 4) ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
    drive_id = None
    try:
        drive_id = gdrive_upload_csv(csv_path)
        print(f"Google Drive ì—…ë¡œë“œ ì™„ë£Œ: {csv_path.name}, id={drive_id}")
    except Exception as e:
        print(f"[Drive] ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

    # 5) ìŠ¬ë™ ì „ì†¡
    text = make_slack_message(rows, prev_rows, change, csv_path, drive_id)
    post_to_slack(text)

    # 6) ë¡œê·¸
    elapsed = time.time() - t0
    print(f"ì´ {len(rows)}ê±´, ê²½ê³¼: {elapsed:.1f}s")
    print(f"CSV: {csv_path}")

if __name__ == "__main__":
    try:
        main()
    except Exception:
        print(traceback.format_exc())
        sys.exit(1)
